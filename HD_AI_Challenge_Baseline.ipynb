{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvPB2gbdgJAOFTSfY7VHlN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEEINSEO-0118/HD_AI_Challenge/blob/main/HD_AI_Challenge_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mej6quaaY48A",
        "outputId": "535ef2bb-c0f4-4919-f2c5-ceb1a7246242"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3RN_GbpXYimi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import bisect\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "file_path = '/content/drive/MyDrive/ai부트캠프/Machine_Learning/DATA/HD_challenge/'\n",
        "train = pd.read_csv(file_path+'train.csv').drop(columns=['SAMPLE_ID'])\n",
        "test = pd.read_csv(file_path+'test.csv').drop(columns=['SAMPLE_ID'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## datetime 컬럼 처리"
      ],
      "metadata": {
        "id": "-l7liY6raRO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datetime 컬럼 처리\n",
        "train.ATA = pd.to_datetime(train['ATA'])\n",
        "test.ATA = pd.to_datetime(train['ATA'])\n",
        "\n",
        "# datetime 변환\n",
        "for df in [train, test]:\n",
        "    df['year'] = df['ATA'].dt.year\n",
        "    df['month'] = df['ATA'].dt.month\n",
        "    df['day'] = df['ATA'].dt.day\n",
        "    df['hour'] = df['ATA'].dt.hour\n",
        "    df['minute'] = df['ATA'].dt.minute\n",
        "    df['weekday'] = df['ATA'].dt.weekday\n",
        "\n",
        "# datetime 컬럼 제거\n",
        "train.drop(columns='ATA', inplace=True)\n",
        "test.drop(columns='ATA', inplace=True)"
      ],
      "metadata": {
        "id": "l-f87yWjZYUF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorical feature encoding"
      ],
      "metadata": {
        "id": "3T4DwsqLaOYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'FLAG']\n",
        "encoders = {}\n",
        "\n",
        "for feature in tqdm(categorical_features, desc = 'Encoding features'):\n",
        "    le = LabelEncoder()\n",
        "    train[feature] = le.fit_transform(train[feature].astype(str))\n",
        "    le_classes_set = set(le.classes_)\n",
        "    test[feature] = test[feature].map(lambda s: '-1' if s not in le_classes_set else s)\n",
        "    le_classes = le.classes_.tolist()\n",
        "    bisect.insort_left(le_classes, '-1')\n",
        "    le.classes_ = np.array(le_classes)\n",
        "    test[feature] = le.transform(test[feature].astype(str))\n",
        "    encoders[feature] = le"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rybCo5Z0ahSW",
        "outputId": "8eba6efb-487c-48ab-a0e1-4a11c1c77a5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding features: 100%|██████████| 6/6 [00:04<00:00,  1.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결측치 처리\n",
        "\n",
        "결측치를 means으로 대충 채운 경우 [U_WIND, V_WIND, AIR_TEMPERATURE, BN] 피쳐들의 중요도가 낮게 나옴.  \n",
        "*MAE = 53.45077523955608*\n",
        "\n",
        "결측치를 다 없애고. origin한 데이터로 예측을 하는 경우에도 중요도는 유사함\n"
      ],
      "metadata": {
        "id": "gAFhyQFya6Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.fillna(train.mean(),inplace= True)\n",
        "test.fillna(train.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "nlxyk1yla8re"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXbgDiiEegZC",
        "outputId": "f970eceb-49f6-4af9-95e4-a01c2c46835a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'DIST', 'ID', 'BREADTH',\n",
              "       'BUILT', 'DEADWEIGHT', 'DEPTH', 'DRAUGHT', 'GT', 'LENGTH',\n",
              "       'SHIPMANAGER', 'FLAG', 'U_WIND', 'V_WIND', 'AIR_TEMPERATURE', 'BN',\n",
              "       'ATA_LT', 'DUBAI', 'BRENT', 'WTI', 'BDI_ADJ', 'PORT_SIZE', 'CI_HOUR',\n",
              "       'year', 'month', 'day', 'hour', 'minute', 'weekday'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습, feature importance 확인"
      ],
      "metadata": {
        "id": "UqD-UkuIbIdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, model_name, X_train, y_train):\n",
        "    print(f'Model Tune for {model_name}')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    feature_importances = model.feature_importances_\n",
        "    sorted_idx = feature_importances.argsort()\n",
        "\n",
        "    plt.figure(figsize = (10, len(X_train.columns)))\n",
        "    plt.title(f'Fequre importance({model_name})')\n",
        "    plt.barh(range(X_train.shape[1]), feature_importances[sorted_idx], align='center')\n",
        "    plt.yticks(range(X_train.shape[1]), X_train.columns[sorted_idx])\n",
        "    plt.xlabel('Importance')\n",
        "    plt.show()\n",
        "\n",
        "    return model, feature_importances\n",
        "\n",
        "X_train = train.drop(columns = 'CI_HOUR')\n",
        "y_train = train.CI_HOUR\n",
        "\n",
        "lgbm_model, lgbm_feature_importances = train_and_evaluate(lgb.LGBMRegressor(), 'LGBM'\n",
        "                                                            , X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BQpstMZjbNdR",
        "outputId": "deda3799-9566-4d8e-8fdb-41e70e7ad32c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Tune for LGBM\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208376 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3931\n",
            "[LightGBM] [Info] Number of data points in the train set: 367441, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 61.877118\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x3000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 85\n",
        "low_importance_features = X_train.columns[lgbm_feature_importances < threshold]\n",
        "\n",
        "X_train_reduced = X_train.drop(columns=low_importance_features)\n",
        "X_test_reduced = test.drop(columns=low_importance_features)"
      ],
      "metadata": {
        "id": "odBmf2UedNUm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm optuna\n",
        "import optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzLrkAEZ-KMw",
        "outputId": "49f77de5-1686-4d05-932c-9788af4a4b13"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.3)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.21)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.12.0 cmaes-0.10.0 colorlog-6.7.0 optuna-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'n_estimators' : 500, 'learning_rate': 0.16, 'max_depth': 25, 'num_leaves': 512,\n",
        "          'min_child_samples' : 50, 'colsample_bytree' : 0.8}\n",
        "\n",
        "lgbm = lgb.LGBMRegressor(**params, random_state = 42)\n",
        "\n",
        "# 5-Fold 설정\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 각 fold의 모델로부터의 예측을 저장할 리스트와 MAE 점수 리스트\n",
        "ensemble_predictions = []\n",
        "scores = []\n",
        "\n",
        "for train_idx, val_idx in tqdm(kf.split(X_train_reduced), total=5, desc=\"Processing folds\"):\n",
        "    X_t, X_val = X_train_reduced.iloc[train_idx], X_train_reduced.iloc[val_idx]\n",
        "    y_t, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # 두 모델 모두 학습\n",
        "    lgbm.fit(X_t, y_t)\n",
        "\n",
        "    # 각 모델로부터 Validation set에 대한 예측을 평균내어 앙상블 예측 생성\n",
        "    val_pred = lgbm.predict(X_val)\n",
        "\n",
        "    # Validation set에 대한 대회 평가 산식 계산 후 저장\n",
        "    scores.append(mean_absolute_error(y_val, val_pred))\n",
        "\n",
        "    # test 데이터셋에 대한 예측 수행 후 저장\n",
        "    lgbm_pred = lgbm.predict(X_test_reduced)\n",
        "    lgbm_pred = np.where(lgbm_pred < 0, 0, lgbm_pred)\n",
        "\n",
        "    ensemble_predictions.append(lgbm_pred)\n",
        "\n",
        "# K-fold 모든 예측의 평균을 계산하여 fold별 모델들의 앙상블 예측 생성\n",
        "final_predictions = np.mean(ensemble_predictions, axis=0)\n",
        "\n",
        "# 각 fold에서의 Validation Metric Score와 전체 평균 Validation Metric Score출력\n",
        "print(\"Validation : MAE scores for each fold:\", scores)\n",
        "print(\"Validation : MAE:\", np.mean(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvYRLdTNdbbc",
        "outputId": "2128d7c9-2732-4eb6-90e2-2d64c856d8e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing folds:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.164012 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.047288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing folds:  20%|██        | 1/5 [01:30<06:00, 90.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079612 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.719969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing folds:  40%|████      | 2/5 [02:51<04:14, 84.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048205 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.754815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing folds:  60%|██████    | 3/5 [04:13<02:47, 83.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050791 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.868218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing folds:  80%|████████  | 4/5 [05:35<01:23, 83.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.995298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing folds: 100%|██████████| 5/5 [06:56<00:00, 83.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation : MAE scores for each fold: [30.843265895947486, 31.422270564696085, 31.68424994752263, 31.266728212572435, 31.101892131818175]\n",
            "Validation : MAE: 31.263681350511366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def optimizer(trial, X, y, K):\n",
        "    # 조절할 hyper-parameter 조합을 적어줍니다.\n",
        "    # template\n",
        "    # num_leaves = trial.suggest_categorical('num_leaves', []) # Grid search의 방법\n",
        "    # max_depth = trial.suggest_int('max_depth', low, high)\n",
        "    # learning_rate = trial.suggest_float('learning_rate', low, high)\n",
        "    num_leaves = trial.suggest_categorical('num_leaves', [128, 256, 512]) # Grid search의 방법\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 25)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
        "    min_child_samples = trial.suggest_int('min_child_samples', 1, 100)\n",
        "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 0.8)\n",
        "\n",
        "\n",
        "    # 원하는 모델을 지정합니다, optuna는 시간이 오래걸리기 때문에 저는 보통 RF로 일단 테스트를 해본 뒤에 LGBM을 사용합니다.\n",
        "    model = lgb.LGBMRegressor(num_leaves = num_leaves,\n",
        "                              max_depth = max_depth,\n",
        "                              learning_rate = learning_rate,\n",
        "                              n_estimators = n_estimators,\n",
        "                              min_child_samples = min_child_samples,\n",
        "                              colsample_bytree = colsample_bytree,\n",
        "                              random_state = 42)\n",
        "\n",
        "\n",
        "    # K-Fold Cross validation을 구현합니다.\n",
        "    folds = KFold(n_splits=K)\n",
        "    losses = []\n",
        "\n",
        "    for train_idx, val_idx in folds.split(X, y):\n",
        "        X_train = X.iloc[train_idx, :]\n",
        "        y_train = y.iloc[train_idx]\n",
        "\n",
        "        X_val = X.iloc[val_idx, :]\n",
        "        y_val = y.iloc[val_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_val)\n",
        "        loss = mean_absolute_error(y_val, preds)\n",
        "        losses.append(loss)\n",
        "\n",
        "\n",
        "    # K-Fold의 평균 loss값을 돌려줍니다.\n",
        "    return np.mean(losses)"
      ],
      "metadata": {
        "id": "i-zXW05e-_qk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "K = 5   # Kfold 수\n",
        "opt_func = partial(optimizer, X=X_train_reduced, y=y_train, K=K)\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\") # 최소/최대 어느 방향의 최적값을 구할 건지.\n",
        "study.optimize(opt_func, n_trials=50) # 50정도의 시행횟수를 추천함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjHYhXTvBPPR",
        "outputId": "a22e9242-8931-418f-d38a-a23d6df1ad27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:37:20,037] A new study created in memory with name: no-name-e170e825-7859-40ff-b4b1-75f4744735af\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040786 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046352 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046497 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045379 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045031 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:39:15,667] Trial 0 finished with value: 32.41418144358808 and parameters: {'num_leaves': 256, 'max_depth': 22, 'learning_rate': 0.20064432589996076, 'n_estimators': 461, 'min_child_samples': 52, 'colsample_bytree': 0.657206113728951}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044527 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007824 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041241 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067833 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042220 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:40:13,899] Trial 1 finished with value: 35.56468103078288 and parameters: {'num_leaves': 512, 'max_depth': 18, 'learning_rate': 0.21049535657280039, 'n_estimators': 164, 'min_child_samples': 49, 'colsample_bytree': 0.6187421396188139}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040616 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042925 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065395 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040735 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040200 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:42:15,606] Trial 2 finished with value: 33.61779229104942 and parameters: {'num_leaves': 512, 'max_depth': 25, 'learning_rate': 0.21088679450842257, 'n_estimators': 355, 'min_child_samples': 64, 'colsample_bytree': 0.5701276884384243}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073133 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045984 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044498 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044619 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044616 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:43:15,034] Trial 3 finished with value: 33.198715944491724 and parameters: {'num_leaves': 128, 'max_depth': 15, 'learning_rate': 0.2278397686121757, 'n_estimators': 374, 'min_child_samples': 34, 'colsample_bytree': 0.7483964005172116}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064784 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039510 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064122 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062770 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:43:53,589] Trial 4 finished with value: 53.206868108519316 and parameters: {'num_leaves': 128, 'max_depth': 16, 'learning_rate': 0.030475722335435433, 'n_estimators': 173, 'min_child_samples': 74, 'colsample_bytree': 0.5291122651865068}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040333 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041685 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039425 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006838 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066286 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:45:14,006] Trial 5 finished with value: 33.024559949473215 and parameters: {'num_leaves': 256, 'max_depth': 19, 'learning_rate': 0.16758761291144933, 'n_estimators': 430, 'min_child_samples': 11, 'colsample_bytree': 0.5547260419385055}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063871 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040898 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041101 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007070 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039273 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:47:11,552] Trial 6 finished with value: 34.06230186926541 and parameters: {'num_leaves': 512, 'max_depth': 24, 'learning_rate': 0.14450007146923216, 'n_estimators': 321, 'min_child_samples': 81, 'colsample_bytree': 0.5411529433537734}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075484 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045488 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046469 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046932 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044043 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:47:25,985] Trial 7 finished with value: 47.1083107088315 and parameters: {'num_leaves': 128, 'max_depth': 16, 'learning_rate': 0.22435841243084811, 'n_estimators': 51, 'min_child_samples': 91, 'colsample_bytree': 0.7063517031690573}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070449 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043713 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043185 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045319 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043665 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:48:22,807] Trial 8 finished with value: 43.01475941237605 and parameters: {'num_leaves': 128, 'max_depth': 22, 'learning_rate': 0.05576685125224577, 'n_estimators': 311, 'min_child_samples': 46, 'colsample_bytree': 0.6591930515908095}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069053 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045523 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043861 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043356 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044187 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:48:45,527] Trial 9 finished with value: 53.0044359417207 and parameters: {'num_leaves': 512, 'max_depth': 10, 'learning_rate': 0.08815810910018407, 'n_estimators': 61, 'min_child_samples': 64, 'colsample_bytree': 0.7227585165228847}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044841 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044705 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074247 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046067 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052037 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:50:18,852] Trial 10 finished with value: 32.446393240246735 and parameters: {'num_leaves': 256, 'max_depth': 21, 'learning_rate': 0.26525331597087937, 'n_estimators': 491, 'min_child_samples': 23, 'colsample_bytree': 0.7996739415919697}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046627 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079372 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046358 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044514 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044174 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:51:51,766] Trial 11 finished with value: 32.59502304264929 and parameters: {'num_leaves': 256, 'max_depth': 21, 'learning_rate': 0.28672717129912395, 'n_estimators': 500, 'min_child_samples': 19, 'colsample_bytree': 0.7893446873849992}. Best is trial 0 with value: 32.41418144358808.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076754 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045308 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045501 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074611 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044964 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:53:26,890] Trial 12 finished with value: 32.121394787327574 and parameters: {'num_leaves': 256, 'max_depth': 21, 'learning_rate': 0.27741906830699437, 'n_estimators': 498, 'min_child_samples': 26, 'colsample_bytree': 0.7942067465873648}. Best is trial 12 with value: 32.121394787327574.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043725 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044421 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074862 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071716 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069971 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:54:49,056] Trial 13 finished with value: 34.21264637198756 and parameters: {'num_leaves': 256, 'max_depth': 23, 'learning_rate': 0.2983010879421756, 'n_estimators': 432, 'min_child_samples': 35, 'colsample_bytree': 0.6715063171805732}. Best is trial 12 with value: 32.121394787327574.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007796 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007783 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041596 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042382 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041760 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:56:02,533] Trial 14 finished with value: 33.24119657147297 and parameters: {'num_leaves': 256, 'max_depth': 20, 'learning_rate': 0.2666783414042515, 'n_estimators': 421, 'min_child_samples': 3, 'colsample_bytree': 0.6103625445423008}. Best is trial 12 with value: 32.121394787327574.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063918 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039590 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040206 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041582 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:57:01,812] Trial 15 finished with value: 35.403529968121575 and parameters: {'num_leaves': 256, 'max_depth': 13, 'learning_rate': 0.16351958022329177, 'n_estimators': 243, 'min_child_samples': 37, 'colsample_bytree': 0.5012710772991329}. Best is trial 12 with value: 32.121394787327574.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059238 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044886 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073507 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044017 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045007 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 14:58:45,135] Trial 16 finished with value: 32.18732948412442 and parameters: {'num_leaves': 256, 'max_depth': 23, 'learning_rate': 0.24520938904173645, 'n_estimators': 454, 'min_child_samples': 59, 'colsample_bytree': 0.7502345659126138}. Best is trial 12 with value: 32.121394787327574.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044113 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045842 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047674 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044044 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071315 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:00:12,241] Trial 17 finished with value: 32.74891797349352 and parameters: {'num_leaves': 256, 'max_depth': 25, 'learning_rate': 0.2571698636837761, 'n_estimators': 385, 'min_child_samples': 60, 'colsample_bytree': 0.7576872171888644}. Best is trial 12 with value: 32.121394787327574.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046972 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071477 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070673 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076553 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045964 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:01:20,171] Trial 18 finished with value: 33.520058317395396 and parameters: {'num_leaves': 256, 'max_depth': 19, 'learning_rate': 0.29782044414468123, 'n_estimators': 248, 'min_child_samples': 96, 'colsample_bytree': 0.7718130311718182}. Best is trial 12 with value: 32.121394787327574.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044304 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075928 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043521 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044896 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045332 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:02:49,034] Trial 19 finished with value: 31.696385146173764 and parameters: {'num_leaves': 256, 'max_depth': 23, 'learning_rate': 0.24278121837449979, 'n_estimators': 466, 'min_child_samples': 23, 'colsample_bytree': 0.7197112749408942}. Best is trial 19 with value: 31.696385146173764.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045036 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076596 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071384 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072137 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070634 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:04:03,999] Trial 20 finished with value: 32.41716644274914 and parameters: {'num_leaves': 256, 'max_depth': 20, 'learning_rate': 0.24421061898935853, 'n_estimators': 388, 'min_child_samples': 22, 'colsample_bytree': 0.7083979136747898}. Best is trial 19 with value: 31.696385146173764.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070937 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047265 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050316 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046071 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071675 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:05:37,298] Trial 21 finished with value: 32.126986278738094 and parameters: {'num_leaves': 256, 'max_depth': 23, 'learning_rate': 0.2474510225489999, 'n_estimators': 464, 'min_child_samples': 29, 'colsample_bytree': 0.7422760863265953}. Best is trial 19 with value: 31.696385146173764.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044296 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014857 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069872 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044594 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044308 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:07:12,492] Trial 22 finished with value: 32.153189630276884 and parameters: {'num_leaves': 256, 'max_depth': 23, 'learning_rate': 0.27039921224309743, 'n_estimators': 496, 'min_child_samples': 27, 'colsample_bytree': 0.7300907916992163}. Best is trial 19 with value: 31.696385146173764.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044062 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070988 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069515 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044091 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044934 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:08:35,625] Trial 23 finished with value: 31.76768627399805 and parameters: {'num_leaves': 256, 'max_depth': 24, 'learning_rate': 0.24179863854586345, 'n_estimators': 464, 'min_child_samples': 11, 'colsample_bytree': 0.7744154779210952}. Best is trial 19 with value: 31.696385146173764.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053061 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052903 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044254 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044653 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045842 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:09:50,955] Trial 24 finished with value: 31.207129495211422 and parameters: {'num_leaves': 256, 'max_depth': 25, 'learning_rate': 0.27748454068376865, 'n_estimators': 409, 'min_child_samples': 1, 'colsample_bytree': 0.7818027446517477}. Best is trial 24 with value: 31.207129495211422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050432 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053402 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046230 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043834 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046859 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:11:07,147] Trial 25 finished with value: 31.697936074878196 and parameters: {'num_leaves': 256, 'max_depth': 25, 'learning_rate': 0.19256330645651135, 'n_estimators': 403, 'min_child_samples': 4, 'colsample_bytree': 0.7731053703262122}. Best is trial 24 with value: 31.207129495211422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046099 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044975 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045819 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045393 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045603 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:12:16,861] Trial 26 finished with value: 31.872459305476895 and parameters: {'num_leaves': 256, 'max_depth': 25, 'learning_rate': 0.18623431589831918, 'n_estimators': 346, 'min_child_samples': 1, 'colsample_bytree': 0.7722809911696389}. Best is trial 24 with value: 31.207129495211422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044375 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044766 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042971 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045413 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043701 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:13:31,934] Trial 27 finished with value: 32.18068443011222 and parameters: {'num_leaves': 256, 'max_depth': 25, 'learning_rate': 0.1870745220729437, 'n_estimators': 406, 'min_child_samples': 11, 'colsample_bytree': 0.6972349816636375}. Best is trial 24 with value: 31.207129495211422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049336 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045389 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070397 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045226 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078786 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:14:16,594] Trial 28 finished with value: 37.56985116957201 and parameters: {'num_leaves': 128, 'max_depth': 24, 'learning_rate': 0.13729414783901586, 'n_estimators': 284, 'min_child_samples': 14, 'colsample_bytree': 0.7262837785002633}. Best is trial 24 with value: 31.207129495211422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055128 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050709 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070205 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1915\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.660527\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069793 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.822064\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046115 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1917\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.044190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-10 15:15:40,403] Trial 29 finished with value: 32.55722845024172 and parameters: {'num_leaves': 512, 'max_depth': 22, 'learning_rate': 0.22570269607738924, 'n_estimators': 341, 'min_child_samples': 5, 'colsample_bytree': 0.7599783430633107}. Best is trial 24 with value: 31.207129495211422.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046271 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1919\n",
            "[LightGBM] [Info] Number of data points in the train set: 293952, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 61.807473\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053010 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1918\n",
            "[LightGBM] [Info] Number of data points in the train set: 293953, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score 62.051334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna가 시도했던 모든 실험 관련 데이터\n",
        "study.trials_dataframe()"
      ],
      "metadata": {
        "id": "5XnSXcOlBWTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best Score: %.4f\" % study.best_value) # best score 출력\n",
        "print(\"Best params: \", study.best_trial.params) # best score일 때의 하이퍼파라미터들"
      ],
      "metadata": {
        "id": "Yl0-Pl0FBZV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실험 기록 시각화\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "kFxaowJ0Bfv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameter들의 중요도\n",
        "optuna.visualization.plot_param_importances(study)"
      ],
      "metadata": {
        "id": "SVbqMdx7Bi2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파라미터에따른 MAE 변화  \n",
        "설정을 하지 않았을 떄 MAE = 53.45077523955608  \n",
        "{'num_leaves': 256, 'max_depth': 15, 'learning_rate': 0.3, 'colsample_bytree' : 0.8}일 때 MAE = 36.97465414001219\n",
        "\n",
        "{'num_leaves': 512, 'max_depth': 25, 'learning_rate': 0.16,'colsample_bytree' : 0.8, 'n_estimators' : 500}일 때 MAE = 30 -> Dacon Leader Board 기준 28.504"
      ],
      "metadata": {
        "id": "t4X2YrWm2J4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission"
      ],
      "metadata": {
        "id": "kglhV-0Ye37K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params\n",
        "best_model = lgb.LGBMRegressor(**best_params,\n",
        "                           random_state = 42)\n",
        "\n",
        "# model finalization : 가장 좋은 성능을 보인 모델로, 전체 데이터 트레이닝\n",
        "best_model.fit(X_train_reduced, y_train)\n",
        "preds = best_model.predict(X_test_reduced)\n",
        "preds"
      ],
      "metadata": {
        "id": "VoVcvtsP-WIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(file_path + 'sample_submission.csv')\n",
        "submission['answer'] = preds\n",
        "submission.to_csv(file_path + \"submission.csv\", index=False)\n",
        "submission"
      ],
      "metadata": {
        "id": "qBMrAorZe6J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0pK3EuNJ_iyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ueT3-8pHpVn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}